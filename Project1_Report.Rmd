---
title: "Global deposition of Beryllium in ice cores"
subtitle: "Draft Report"
author: "Hoang Long Nguyen and Dmytro Perepolkin"
date: "2023-01-25"
output: 
  html_document: 
    highlight: pygments
    theme: flatly
---

```{r setup, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("corrgram")
library(tidyverse)
library(corrgram) # visualisation of correlations
library(lmtest)  # more linear regression tools
library(naniar) # missing data analysis
library(tsibble) # time series tibbles
library(fable) # tsibble-based forecasting
library(fabletools) #data structures for fable
library(feasts) # feature extraction for time series
library(hrbrthemes) #ggplot styling

ggplot2::theme_set(hrbrthemes::theme_ipsum_rc())
```

# Introduction

## Data description

The data file production_data.csv contain 400 observations on 8 variables. 6 of the variables are synthetic production rate of 10Be for the last 8000 years from different regions of the globe. These regional synthetic production rate are based on a production model that can simulate theoretical production rate at each latitude and height (km). We generate the production rate and combine them (summation) into different regions. Therefore, correlation are expected between neighboring regions. Beside the regional correlation, there are also time autocorrelation in the dataset.

## Variable description

|variable| description|
|--|--|
|age|time before 1950 [years]|
|Q_trop_high |   10Be production rate in the troposphere at high latitude (60-90°) [atoms/cm2/s]|
|Q_trop_mid |   10Be production rate in the troposphere at mid latitude (30-60°) [atoms/cm2/s]|
|Q_trop_low |   10Be production rate in the troposphere at low latitude (0-30°) [atoms/cm2/s]|
|Q_stra_high |  10Be production rate in the stratosphere at high latitude (60-90°) [atoms/cm2/s]|
|Q_stra_mid  |  10Be production rate in the stratosphere at mid latitude (30-60°) [atoms/cm2/s]|
|Q_stra_low  |  10Be production rate in the stratosphere at low latitude (0-30°) [atoms/cm2/s]|
|EDML        |  10Be flux [10^6 atoms/cm2/year] to Antarctica measured at the EDML ice core [normalized]|
|GRIP        |  10Be flux [10^6 atoms/cm2/year] to Greenland measured at the GRIP ice core [normalized]|

The variables EDML and GRIP (10Be flux) were normalized to have the same mean as the sum of 10Be production rate from all the regions over the last 8000 years.
The goal is to analyse how much each region contributes to the 10Be fluxes to either Greenland or Antarctica.

# Exploratory Data Analysis

## Correlation structure

First we load the data and look at it.

```{r}
icecore <- read_csv("data/production_data.csv", show_col_types = FALSE)
head(icecore)
```

Lets explore the correlation structure among the covariates.

```{r}
# removing ID variable and the dependent variables for now
varnames<- setdiff(names(icecore), c("age", "EDML", "GRIP"))
corrgram::corrgram(icecore[,varnames], order="PCA",
         main="Correlogram for the icecore data",
         lower.panel=panel.ellipse, upper.panel=panel.pie,
         diag.panel=panel.minmax, text.panel=panel.txt)
```

All independent variables are strongly correlated between themselves. Reordering by PCA identifies the groupings which make sense (by latitude).

## Missing values

There's some missingness in the data. Let's have a look

```{r, message=FALSE, warning=FALSE}
naniar::vis_miss(icecore)
```

The missingness is present only in the response variables EDML and GRIP and only the fist few observations, i.e. it is missing not-at-random.

## Time aspect

We will take somewhat closer look at the time series aspect of the data. First of all, since this is the geology-related data, the age is measured backwards, which means that age=0 is actually the last (most recent) observation. Is the age equally spaced? Yes, it is equi-spaced by 20 years.

```{r}
unique(diff(icecore$age))
```

Let's rearrange the data and add an index. We will turn this tibble into the time series object (using class `tsibble`).

```{r}
icecore_df <- icecore %>% 
  mutate(time=-age, .before = 1) %>% 
  select(-age) %>% 
  arrange(time) 
```

Lets plot the response variables

```{r}
icecore_df %>% 
  select(time, EDML, GRIP) %>% 
  pivot_longer(-time, names_to="core", values_to="value") %>%
  ggplot()+
  geom_line(aes(time,value, color=core))+
  facet_wrap(vars(core), ncol=1)
```

There does not appear to be a clear seasonality (after all the data is sampled every 20 years), but we can clearly see that there's a trend. 

# Train-test split

First, we will create the training and test set, separating the period for which we dont have the response variable, but have the predictor variables

```{r}
idx_GRIP_train <- !is.na(icecore_df$GRIP)
idx_EDML_train <- !is.na(icecore_df$EDML)

GRIP_train_ts <- icecore_df %>%
  select(-EDML) %>% 
  filter(idx_GRIP_train) %>%
  as_tsibble(index = time)
GRIP_test_ts <- icecore_df %>% 
  select(-GRIP, -EDML) %>% 
  filter(!idx_GRIP_train) %>%
  as_tsibble(index = time)

EDML_train_ts <- icecore_df %>%
  select(-GRIP) %>% 
  filter(idx_EDML_train) %>%
  as_tsibble(index = time)
EDML_test_ts <- icecore_df %>% 
  select(-GRIP, -EDML) %>% 
  filter(!idx_EDML_train) %>%
  as_tsibble(index = time)

```

# Greenland (GRIP) ice core 

## Simple Forecasting

```{r}
trend_mod_GRIP <- GRIP_train_ts %>%
  model(linear=TSLM(GRIP ~trend()),
        piecewise=TSLM(GRIP~trend(knots=c(-7200,-2200)))
        )

fc_trend_mod_GRIP <- trend_mod_GRIP %>% 
  fabletools::forecast(h=20)
```

```{r}
GRIP_train_ts %>% 
  autoplot(GRIP)+
  geom_line(data=fitted(trend_mod_GRIP),
            aes(y=.fitted, color=.model))+
  autolayer(fc_trend_mod_GRIP, alpha=0.6, level=95)+
  labs(title="Trend models and forecasts")
```

## Smoothing

Lets try some time series smoothing First, here's a 9 period moving average. Pretty strong trend.

```{r}
GRIP_train_ts %>% 
  mutate(`GRIP-9-MA`=slider::slide_dbl(GRIP, mean, 
             .before=4, .after=4, .complete=TRUE)) %>% 
  autoplot(GRIP)+
  geom_line(aes(y=`GRIP-9-MA`), color="orange")

```

Right now all 9 points in the smoothing window are equally weighted. Exponential smoothing creates a kernel of weights which attenuate away from the current point backward. Here's a model with simple exponential smoothing.

```{r}
es_mod_GRIP <- GRIP_train_ts %>% 
  model(ETS(GRIP~error("A")+trend("N")))
fc_es_mod_GRIP <- es_mod_GRIP %>% 
  fabletools::forecast(h=20)

fc_es_mod_GRIP %>% 
  autoplot(GRIP_train_ts)+
  geom_line(data=augment(es_mod_GRIP),aes(y=.fitted), col="orange")+
  labs(title="Simple exponential smoothing")
```

Let's try and incorporate the trend. This is using Holt's linear trend method.

```{r}
es_mod_GRIP <- GRIP_train_ts %>% 
  model(AAN=ETS(GRIP~error("A")+trend("A")))
fc_es_mod_GRIP <- es_mod_GRIP %>% 
  fabletools::forecast(h=20)

fc_es_mod_GRIP %>% 
  autoplot(GRIP_train_ts)+
  geom_line(data=augment(es_mod_GRIP),aes(y=.fitted), col="orange")+
  labs(title="AAN exponential smoothing")
```

As you can see the forecast picked up the downward sloping global linear trend. 

Damped linear trend method corrects the infinite Holt's trend projected into the future and instead attenuates the trend towards a flat line in the remote future. Let's add it and compare.

```{r}
es_mod_GRIP <- GRIP_train_ts %>% 
  model(AAN=ETS(GRIP~error("A")+trend("A")),
        AAdN=ETS(GRIP~error("A")+trend("Ad", phi=0.9)))
fc_es_mod_GRIP <- es_mod_GRIP %>% 
  fabletools::forecast(h=20)

fc_es_mod_GRIP %>% 
  autoplot(GRIP_train_ts)+
  geom_line(data=augment(es_mod_GRIP),aes(y=.fitted), col="orange")+
  labs(title="AAN vs AAdN exponential smoothing")
```


## Time series regression

Let's try to build a regression model. The time-indexed regression model of the form

$$y_t=\beta_0+\beta_1x_{1,t}+\beta_2x_{2,t}+\dots+\beta_kx_{k,t}+\varepsilon_t.$$


It makes the following assumptions about the errors $(\varepsilon_1,\varepsilon_2,\dots,\varepsilon_T)$:

- errors are unbiased (having a mean of zero)
- errors are not autocorrelated (there's no remaining trend)
- errors are not related to the preditors (all signal has been extracted)
- errors are normally distributed with constant variance (for the purposes of making predictive intervals)

```{r}
all_mod_GRIP  <- GRIP_train_ts %>%  
  model(TSLM(GRIP~Q_trop_high+Q_trop_mid+Q_trop_low+
               Q_stra_high+Q_stra_mid+Q_stra_low)) 
report(all_mod_GRIP)
```

None of the predictors is significant. How nice! Let's see the predicted values

```{r}
augment(all_mod_GRIP) %>% 
  ggplot(aes(x=time))+
  geom_line(aes(y=GRIP, color="Data"))+
  geom_line(aes(y=.fitted, color="Fitted"))+
  scale_color_manual(values=c(Data="black", Fitted="orange"))
```

```{r}
augment(all_mod_GRIP) %>% 
  ggplot(aes(x=GRIP,y=.fitted))+
  geom_point()+
  geom_abline(intercept = 0, slope = 1)
```


```{r}
all_mod_GRIP %>% gg_tsresiduals()
```

The plot shows significant autocorrelation in the residuals. We can try and plot the residuals against the covariates.

```{r}
icecore_df %>% 
  left_join(residuals(all_mod_GRIP), by="time") %>% 
  pivot_longer(starts_with("Q_"), names_to = "covariate", values_to="value") %>% 
  ggplot(aes(x=value, y=.resid))+
  geom_point()+
  facet_wrap(vars(covariate), scales = "free_x")+
  labs(title="Residuals vs predictors")
```

Lets plot our residuals against the fitted values

```{r}
augment(all_mod_GRIP) %>% 
  ggplot(aes(x=.fitted, y=.resid))+
  geom_point()+labs(title="Residuals vs fitted")
```

```{r}
glance(all_mod_GRIP) %>% 
  select(adj_r_squared, CV, AIC, AICc, BIC)
```

```{r}
fc_all_mod_GRIP <- fabletools::forecast(all_mod_GRIP,
                                        new_data=GRIP_test_ts)
GRIP_train_ts %>% 
  autoplot(GRIP)+
  autolayer(fc_all_mod_GRIP)+
  labs(title="GRIP core readings and forecast")
```

## ARIMA regression

There seems to be quite a lot of signal left in the error term of our regression. We can try to extract this signal by fitting an ARIMA model to the residuals. Let's start with a single covariate:

$$y_t=\beta_0+\beta_1x_t+\eta_t$$

where $\eta_t$ is an ARIMA model. The order of the model can be specified explicitly, but can also be left up to the engine to select.

```{r}
ARIMA_mod_GRIP <- GRIP_train_ts %>% 
  model(ARIMA(GRIP~Q_stra_high))
report(ARIMA_mod_GRIP)
```

The function picked the linear model with ARIMA(2,1,2) errors for us. Note that the intercept is gone due to the differencing. The way we can interpret these coefficients is:

$$
\begin{gathered}
y_t=1.153x_t+ \eta_t,\\
\eta_t=-0.023\eta_{t-1}+0.2080\eta_{t-2}+\varepsilon_t-0.2503\varepsilon_{t-1}-0.6374\varepsilon_{t-2},\\
\varepsilon_t \sim NID(0,0.05513)
\end{gathered}
$$

```{r}
ARIMA_mod_GRIP %>% gg_tsresiduals()
augment(ARIMA_mod_GRIP) %>% 
  features(.innov, ljung_box, dof=3, lag=8)
```
This is really good! The residuals looks nice and the forecast should be sensible. Lets predict!

```{r}
fabletools::forecast(ARIMA_mod_GRIP, new_data=GRIP_test_ts) %>% 
  autoplot(GRIP_train_ts)+
  labs("ARIMA regression forecast")
```

We should now see if we can improve the goodness of fit by adding more covariates. As you can remember from the correlogram plot, the covariates from the same latitude (high, med, low) vere strongly correlated. Perhaps we could add only one of each.

```{r}
ARIMA_mods <-GRIP_train_ts %>% 
  model("stra_high"=ARIMA(GRIP~Q_stra_high),
        "trop_high"=ARIMA(GRIP~Q_trop_high),
        "all_stra"=ARIMA(GRIP~Q_stra_high+Q_stra_mid+Q_stra_low),
        "all_trop"=ARIMA(GRIP~Q_trop_high+Q_trop_mid+Q_trop_low),
        "all_high"=ARIMA(GRIP~Q_trop_high+Q_stra_high),
        "all_highmid"=ARIMA(GRIP~Q_trop_high+Q_stra_high+Q_trop_mid+Q_stra_mid),
        "all_highlow"=ARIMA(GRIP~Q_trop_high+Q_stra_high+Q_trop_low+Q_stra_low),
        "all"=ARIMA(GRIP~Q_trop_high+Q_stra_high+Q_trop_mid+Q_stra_mid+Q_stra_low+Q_trop_low)
        )
glance(ARIMA_mods)
```

Looking at the AIC or the AICc, the best model seems to be with the variables from high latitude ("Allhigh"), while BIC (which penalizes model complexity a little more) favors our original model with a single high latitude stratosphere variable("Strahigh").

Lets look at the "Allhigh" model details.

```{r}
GRIP_allhigh_mod <- select(ARIMA_mods, "all_high")

GRIP_allhigh_mod %>% report()
```
Lets look at the residuals.

```{r}
gg_tsresiduals(GRIP_allhigh_mod)+
  labs(title="Residuals diagnostic plots",
       subtitle = "Allhigh model")
```


Just awesome! No autocorrelation in residuals, nice distribution. No obvious pattern. A few more diagnostic plots to check the residuals.

```{r}
augment(GRIP_allhigh_mod) %>% 
  ggplot(aes(x=GRIP,y=.fitted))+
  geom_point()+
  geom_abline(intercept = 0, slope = 1)+
  labs(title="Predicted vs fitted",
       subtitle = "Allhigh model")
```

```{r}
icecore_df %>% 
  left_join(residuals(GRIP_allhigh_mod), by="time") %>% 
  pivot_longer(starts_with("Q_"), names_to = "covariate", values_to="value") %>% 
  ggplot(aes(x=value, y=.resid))+
  geom_point()+
  facet_wrap(vars(covariate), scales = "free_x")+
  labs(title="Residuals vs predictors", subtitle = "Allhigh model")
```

Lets plot our residuals against the fitted values

```{r}
augment(GRIP_allhigh_mod) %>% 
  ggplot(aes(x=.fitted, y=.resid))+
  geom_point()+labs(title="Residuals vs fitted", subtitle = "Allhigh model")
```

No particular pattern here. All good, it seems.

## Cross-validation

We will use time series cross-validation to decide which model to use for prediction. We cross-validate the performance of the simple "Strahigh" model against the more complex "Allhigh".

```{r}
GRIP_train_stretched <- GRIP_train_ts %>% 
  stretch_tsibble(.init=100, .step=50) 
GRIP_cv_mod <- GRIP_train_stretched %>% 
  model("strahigh"=ARIMA(GRIP~0+pdq(2,1,2)+Q_stra_high),
        "allhigh"=ARIMA(GRIP~0+pdq(2,1,2)+Q_stra_high+Q_trop_high))
```

We now prepare the validation sets and predict on them, calculating the performance. We will predict 16 observations at a time (the size of our test set).

```{r}
GRIP_cv_valid_ts <- new_data(GRIP_train_stretched, n=16) %>% 
  left_join(GRIP_train_ts, by="time")

GRIP_cv_mod_fc <- fabletools::forecast(GRIP_cv_mod, new_data=GRIP_cv_valid_ts) %>% 
  group_by(.id, .model) %>% 
  mutate(h=row_number()) %>% 
  ungroup() %>% 
  as_fable(response="GRIP", distribution=GRIP)

GRIP_cv_mod_fc %>% 
  fabletools::accuracy(GRIP_train_ts, by=c("h", ".model")) %>% 
  group_by(.model, .type) %>% 
  summarize_all(mean)
```
The original model is better in every respect! BIC was right (as always).

Let's predict using the `Q_stra_high` variable.

```{r}
ARIMA_mod_GRIP %>% 
  fabletools::forecast(new_data=GRIP_test_ts) %>% 
  autoplot(GRIP_train_ts)+
  labs(title="Prediction from ARIMA model",
       subtitle="Strahigh model")
```

# Antarctica (EDML) ice core

## ARIMA regression

Let's save ourselves some time and go straight to the ARIMA regression for EDML response variable

```{r}
all_mod_EDML <- EDML_train_ts %>% 
  model("stra_low"=ARIMA(EDML~Q_stra_low),
        "trop_low"=ARIMA(EDML~Q_trop_low),
        "all_stra"=ARIMA(EDML~Q_stra_high+Q_stra_mid+Q_stra_low),
        "all_trop"=ARIMA(EDML~Q_trop_high+Q_trop_mid+Q_trop_low),
        "all_low"=ARIMA(EDML~Q_stra_low+Q_trop_low),
        "all_lowmid"=ARIMA(EDML~Q_stra_low+Q_trop_low+Q_stra_mid+Q_trop_mid),
        "all_lowhigh"=ARIMA(EDML~Q_stra_low+Q_trop_low+Q_stra_high+Q_trop_high),
        "all"=ARIMA(EDML~Q_stra_high+Q_stra_mid+Q_stra_low+
                      Q_trop_high+Q_trop_mid+Q_trop_low))
glance(all_mod_EDML)
```

BIC prefers the "lowmid" model, while the AIC favors the "lowhigh" model.

Let's pick one of them and look at the residuals.

```{r}
all_mod_EDML %>% select("all_lowmid") %>% 
  gg_tsresiduals()
```

Residuals look largely ok with only two periods "sticking out" of the confidence bands: at lags 14 and 22 (no obvious reason why). I am concerned about the non-stationary variance of the residuals and, therefore, slightly irregular shape of the error distribution. 

```{r}
all_mod_EDML %>% select("all_lowmid") %>% 
  report()
```

This is a pretty complex model: 4 covariates, 4 lags, and 2 moving averages. 

The alternative model's residuals

```{r}
all_mod_EDML %>% select("all_lowhigh") %>% 
  gg_tsresiduals()
```

Here we have a significant autoregression at the lag 7 and 22.

```{r}
all_mod_EDML %>% select("all_lowhigh") %>% 
  report()
```
This is somewhat simpler model with 3 lags, 1 moving average and 4 variables.

## Cross-validation

We will employ the "stretching window" cross-validation scheme to assess the performance of the selected number of models on the training data (effectively treating part of it as a validation set). Here we will set the initial training set to be 100 observations and then at every iteration we will add 61 to the training set, always predicting 61 observations (equivalent to the size of the test set we are trying to predict).

```{r}
EDML_stretched <- EDML_train_ts %>% 
  stretch_tsibble(.init=100, .step=61) 
EDML_cv_mod <- EDML_stretched %>% 
  model("all_lowmid"=ARIMA(EDML~0+pdq(4,0,2)+Q_stra_low+Q_trop_low+Q_stra_mid+Q_trop_mid),
        "all_lowhigh"=ARIMA(EDML~0+pdq(3,0,1)+Q_stra_low+Q_trop_low+Q_stra_high+Q_trop_high))
```

```{r}
EDML_cv_valid_ts <- new_data(EDML_stretched, n=61) %>% 
  left_join(EDML_train_ts, by="time")

EDML_cv_mod_fc <- fabletools::forecast(EDML_cv_mod, new_data=EDML_cv_valid_ts) %>% 
  group_by(.id, .model) %>% 
  mutate(h=row_number()) %>% 
  ungroup() %>% 
  as_fable(response="EDML", distribution=EDML)

EDML_cv_mod_fc %>% fabletools::accuracy(EDML_train_ts, by=c("h", ".model")) %>% 
  group_by(.model, .type) %>% 
  summarize_all(mean)
```

The "lowhigh" is slightly better on all metrics. 

```{r}
all_mod_EDML %>% select(all_lowhigh) %>% 
  fabletools::forecast(new_data=EDML_test_ts) %>% 
  autoplot(EDML_train_ts)+
  labs(title="Prediction from ARIMA model",
       subtitle="Lowhigh model")
```

