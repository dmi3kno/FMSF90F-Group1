---
title: "Predicting beta-carotene content in plasma"
subtitle: "Project 2"
author: 
 - name: Zaide Montes
   affiliations:
     - name: Lund University
       department: Department of Biology
       address: S√∂lvegatan 12, S-223 62 Lund, Sweden
 - name: Dmytro Perepolkin
   affiliations:
     - name: Lund University
       department: Centre for Environmental and Climate Science
       address: S√∂lvegatan 37, S-223 62 Lund, Sweden
bibliography: Project2_plasma.bib
format: 
  titlepage-pdf:
    documentclass: scrbook
    classoption: ["oneside", "open=any"]
    number-sections: true
    titlepage: classic-lined 
    titlepage-logo: "img/logo.png"
    titlepage-footer: |
      Group 1
      Lund University\
      Lund, Sweden\
      [https://lu.se](https://lu.se)\
    titlepage-theme:
      elements: ["\\titleblock", "\\authorblock", "\\vfill", "\\logoblock", "\\footerblock"]
      page-align: "center"
      title-style: "doublelinewide"
      title-fontsize: 30
      title-fontstyle: "uppercase"
      title-space-after: "0.1\\textheight"
      subtitle-fontstyle: ["Large", "textit"]
      author-style: "plain"
      author-sep: "\\hskip1em"
      author-fontstyle: "Large"
      author-space-after: "2\\baselineskip"
      affiliation-style: "numbered-list-with-correspondence"
      affiliation-fontstyle: "large"
      affiliation-space-after: "0pt"
      footer-style: "plain"
      footer-fontstyle: ["large", "textsc"]
      footer-space-after: "0pt"
      logo-size: "0.25\\textheight"
      logo-space-after: "1cm"
fig-height: 5
fig-width: 7
fig-align: "center"
---

```{r setup, message=FALSE}
#| message: false
#install.packages("corrgram")
library(tidyverse)
library(broom)
library(corrgram) # visualisation of correlations
library(lmtest)  # more linear regression tools
library(hrbrthemes) #ggplot styling
library(GGally) # Pair plot
library(ggplot2) # ggplot 2
library(hrbrthemes) # theme for ggplot
library(kableExtra)
library(leaps)
library(glmnet)
<<<<<<< HEAD
library(patchwork)
library(plotmo)
=======
library(randomForest) # for random forest chapter
library(pls) # for principal component regression
library(rsample) # for cross-validation
library(modelr) # evaluation of models
>>>>>>> 34801284346ffe48f73cb759ff24bf18807a9e9d
ggplot2::theme_set(hrbrthemes::theme_ipsum_rc())

extrafont::loadfonts(device = "all", quiet = TRUE)

knitr::opts_chunk$set(dev = 'png')
options(device = function(file, width, height) {
  png(tempfile(), width = width, height = height)
})
```

# Introduction

## Data description

The dataset is from `gamlss.data` package [@harrell2002PlasmaRetinolBetaCarotene]. It is a cross-sectional study to investigate the relationship between personal characteristics and dietary factors, and plasma concentrations.

An original data frame has 315 observations of the following variables

| Variable        | Description                                             |
|-----------------|---------------------------------------------------------|
| `age`           | age(years)                                              |
| `sex`           | sex, 1=male, 2=female                                   |
| `smokstat`      | smoking status 1=never, 2=former, 3=current Smoker      |
| `bmi`           | body mass index weight/(height\^2)                      |
| `vituse`        | vitamin use 1=yes, fairly often, 2=yes, not often, 3=no |
| `calories`      | number of calories consumed per day                     |
| `fat`           | grams of fat consumed per day                           |
| `fiber`         | grams of fiber consumed per day                         |
| `alcohol`       | number of alcoholic drinks consumed per week            |
| `cholesterol`   | cholesterol consumed (mg per day)                       |
| `betadiet`      | dietary beta-carotene consumed (mcg per day)            |
| `retdiet`[^1]   | dietary retinol consumed (mcg per day)                  |
| `betaplasma`    | plasma beta-carotene (ng/ml)                            |
| `retplasma`[^2] | plasma retinol (ng/ml)                                  |

[^1]: Not present in the current version of the dataset

[^2]: Not present in the current version of the dataset

We import the data

```{r}
plasma_df <- read_csv("data/plasma.txt", show_col_types = FALSE)
```

> Observational studies have suggested that low dietary intake or low plasma concentrations of retinol, beta-carotene, or other carotenoids might be associated with increased risk of developing certain types of cancer... We designed a cross-sectional study to investigate the relationship between personal characteristics and dietary factors, and plasma concentrations of retinol, beta-carotene and other carotenoids. [@harrell2002PlasmaRetinolBetaCarotene]

# Multivariate regression

 glmnet requires a model-matrix as the model specification.
 A model matrix is a matrix with a column for each predictor (=x-variable) in the model (including the extra columns for polynomials, dummy variables etc), and each row is for a unique observation.
 Sometimes the model-matrix includes a column for the intercept, in glmnet it should (typically) not.

```{r}
#head(plasma_df)
x <- model.matrix(log(betaplasma) ~ ., plasma_df)[, -1]
#head(x)
y <- log(plasma_df$betaplasma)
#head(y)
```

```{r}
# Grid of lambdas
grid <- 10^seq(5, -2, length = 100) #grid 

# Run ridge regression (alpha =0) for each lambda in grid
ridge.mod <- glmnet(x, y, alpha = 0, lambda = grid)
```

The `ridge.mod` contains `r dim(coef(ridge.mod))[1]` rows and `r dim(coef(ridge.mod))[2]` columns corresponding to the number of $\lambda$ values we created earlier.

```{r}
# Prepare for cross validation by splitting the data in training and validation set
set.seed(42)
train <- sample(1:nrow(x), nrow(x) / 2)
test <- (-train)
y.test <- y[test]

```

```{r}
# Fit ridge regression on the training data, for our grid of lambda
ridge.mod <- glmnet(x[train, ], y[train], alpha = 0,
    lambda = grid, thresh = 1e-12)
# Find predictions for our testdata for a specific lambda (here lambda =4)
ridge.pred <- predict(ridge.mod, s = 4, newx = x[test, ])

```

<<<<<<< HEAD
The MSE for the $\lambda = 4$ is `r mean((ridge.pred - y.test)^2)`. @fig-ridge-plot1 shows the ridge model coefficients are approaching to zero. 
=======
The MSE for the $\lambda = 4$ is `r mean((ridge.pred - y.test)^2)`. @fig-ridge-plot1 shows the ridge model ceofficients that ,mksjdhfgkdfgjh
>>>>>>> 34801284346ffe48f73cb759ff24bf18807a9e9d
 
```{r}
#| label: fig-ridge-plot1
#| out-width: 80%
#| fig-cap: The ridge regression coefficients are displayed for the Plasma data set, as a function of Œª. 
#plot(ridge.mod,xvar="lambda",lwd=1.5)
plot_glmnet(ridge.mod,xvar="lambda",lwd=1.5)
```
```{r}
#| label: fig-ridge-plot2
#| fig-width: 10
#| fig-height: 5
#| out-width: 80%
#| fig-cap: A graph of the ridge model coefficients for different lambdas. The dashed lines are the logùúÜvalues corresponding to the ùúÜmin (left dashed line) and ùúÜ1ùë†ùëí(right dashed line).

set.seed(1)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 0)
plot(cv.out)
```

```{r}
# Choose the best:
bestlam <- cv.out$lambda.min
```

The best lambda is $\lambda=`r bestlam`$.

```{r}
# MSE associated with this lambda
ridge.pred <- predict(ridge.mod, s = bestlam,
    newx = x[test, ])
mean((ridge.pred - y.test)^2)
```
The R-squared turns out to be 0.4319724. That is, the best model which explains 34.19% of the variation in the response values of the training data.


```{r}
# Fit lasso model: alpha=1
# Use only the training data
lasso.mod <- glmnet(x[train, ], y[train], alpha = 1,
    lambda = grid)
```

```{r}
#| label: fig-Lasso-plot1
#| fig-width: 10
#| fig-height: 5
#| out-width: 80%
#| fig-cap: The Lasso regression coefficients are displayed for the Plasma data set, as a function of Œª.
plot_glmnet(lasso.mod,label=TRUE,xvar="lambda",lwd=1.5)
```

```{r}
#| label: fig-Lasso-plot2
#| fig-width: 10
#| fig-height: 5
#| out-width: 80%
#| fig-cap: The Lasso regression coefficients are displayed for the Plasma data set, as a function of ‚à•Œ≤ÀÜŒªL‚à•1/‚à•Œ≤ÀÜ‚à•1.
plot_glmnet(lasso.mod,label=TRUE,lwd=1.5)
```

```{r}
#| label: fig-Lasso-plot3
#| fig-width: 10
#| fig-height: 5
#| out-width: 80%
#| fig-cap:  The figure illustrates the cross validation process for picking the best lambda in lasso regression. The dashed lines are the logùúÜvalues corresponding to the ùúÜmin (left dashed line) and ùúÜ1ùë†ùëí(right dashed line).
set.seed(1)
cv.out <- cv.glmnet(x[train, ], y[train], alpha = 1)
plot(cv.out)
```
```{r}
bestlam2 <- cv.out$lambda.min
```

The best lambda value that minimizes the test MSE turns out to be  $\lambda=`r bestlam2`$.

```{r}
# compute the test error for this choice of lambda or MSE associated with this lambda
lasso.pred <- predict(lasso.mod, s = bestlam2,
    newx = x[test, ])
mean((lasso.pred - y.test)^2)
```

The R-squared turns out to be 0.4319724. That is, the best model which explains 34.19% of the variation in the response values of the training data.

```{r}
# Now fit on full data using the lambda selected by cross-validation
out <- glmnet(x, y, alpha = 1, lambda = grid)

lasso.coef <- predict(out, type = "coefficients",
    s = bestlam2)[1:13, ]
lasso.coef
lasso.coef[lasso.coef != 0]
```


The variance of ridge regression is slightly lower than the variance of the lasso. Consequently, the minimum MSE of ridge regression is slightly smaller than that of the lasso. In addition, the  models generated from the lasso were  much easier to interpret than those produced by ridge regression. The lasso yields sparse models that involve only a subset of the variables. Hence, depending on the value of Œª, the lasso can produce a model involving any number of variables. In contrast, ridge regression will always include all of the variables in the model, although the magnitude of the coefficient estimates will depend on Œª. In the lasso regression we observed that the variables that influenced more in the model are the alcohol, fiber and fat (Figurex). To sum up, the lasso should perform better in a setting where a relatively small number of predictors have significant coefficients, and the remaining predictors have very small coefficients or that equal zero.  In contrast, the ridge regression will perform better when the response is a function of many predictors, all with roughly equal-sized coefficients.









```{r}
#Principal components regression

```




# Random Forest

We will now use the random forest algorithm implemented in `randomForest` package in R.

```{r}
rf_fit <- randomForest(log(betaplasma)~., data=plasma_df,
                       subset = train, mtry=12, importance=TRUE)
```

The parameter `mtry` determines how many columns are consered for each split. We will have to cross-validate this parameter to make sure we are not overfitting to our dataset. For now, we try to split at each one of the variables. The @fig-rf-predicted-true1 shows the predicted values against the true values for the test portion of our dataset.

```{r}
#| label: fig-rf-predicted-true1
#| out-width: 80%
#| fig-cap: "Predicted vs true values for random forest algorithm"
rf_pred <- predict(rf_fit, newdata = plasma_df[test,])
plot(rf_pred, log(plasma_df$betaplasma)[test],
     ylab="log(betaplasma)", xlab="predicted")
abline(0,1)
```

The test MSE for random forest is `r mean((rf_pred-log(plasma_df$betaplasma[test]))^2)`, which is pretty impressive. As for any tree-based algorithm, interpretability is usually an issue. We can use the special function in the `randomForest` package to see which variables were most frequently used in the tree splits (@fig-rf-varimp1).


```{r}
#| label: fig-rf-varimp1
#| out-width: 80%
#| fig-cap: "Variable importance plot for random forest with mtry 12"
varimp_m <- importance(rf_fit) #matrix form
varImpPlot(rf_fit, main="")
```

It seems like `r glue::glue_collapse(names(sort(varimp_m[,1], decreasing = TRUE)[1:5]), sep=", ", last=", and ")` are the most important variables for predicting the level of beta-carotene in plasma.

We will now determine the best value of `mtry` parameter to use in our random forest model. @fig-rfcv shows the out-of-fold MSE for the models with different `mtry`.  

```{r}
#| label: fig-rfcv
#| fig-cap: "Cross-validated performance of random forest"
#| out-width: "80%"
set.seed(42)
cvrf_obj <- randomForest::rfcv(x, y)
with(cvrf_obj, plot(n.var, error.cv, log="x", type="o", lwd=2))
bestvars <- which.min(cvrf_obj$error.cv)
```

It seems like the model with `r paste("mtry=", cvrf_obj$n.var[bestvars])` had the best out-of-fold performance. The @fig-rfcv-bst-predactual shows the predicted vs the actual values from the best model.

```{r}
#| label: fig-rfcv-bst-predactual
#| fig-cap: "Predicted vs actual values for the best model"
#| out-width: "80%"
plot(cvrf_obj$predicted[[bestvars]], y, xlab="predicted", ylab="actual")
abline(0,1)
```

This means that our original model was right and we can report that the best out-of-fold estimate of MSE for the random forest model is `r cvrf_obj$error.cv[bestvars]`.



# References
